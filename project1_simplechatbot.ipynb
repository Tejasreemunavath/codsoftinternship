{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoe6qdvtIHCPWTUrem3Z97",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tejasreemunavath/codsoftinternship/blob/project1/project1_simplechatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "JU25tu-us0ek"
      },
      "outputs": [],
      "source": [
        "import numpy as np ##used for numerical computations\n",
        "import nltk ##library for NLp\n",
        "import string ## process and handle strings in python\n",
        "import random ##generates random responses."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f=open('chatbot.txt','r',errors ='ignore')\n",
        "raw_doc=f.read()\n",
        "raw_doc=raw_doc.lower()\n",
        "nltk.download('punkt')#This tokenizer divides a text into a list of sentences by using an unsupervised algorithm\n",
        "nltk.download('wordnet')#arge lexical database of words, senses, and their semantic relations.\n",
        "sent_tokens = nltk.sent_tokenize(raw_doc)#coverts doc to sentences\n",
        "word_tokens =nltk.word_tokenize(raw_doc)#converts doc to words."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYqMCBf4uW3h",
        "outputId": "2421240f-f3d7-46bf-8268-fa8ac5cb0b03"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXAMPLE OF SENTENCE TOKENS"
      ],
      "metadata": {
        "id": "sEzYbaMmzIJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokens[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG9UK2PfzFGe",
        "outputId": "287f2f54-b03b-4806-e3d3-656647d465a0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['freedom fighters in india\\n\\n\\n\\nindia gained independence from british rule on august 15, 1947, a significant day that occurred almost 75 years ago.',\n",
              " 'it was the result of a number of movements and conflicts that raged all through the period of british administration, including the famous uprising of 1857. many revolutionary indian freedom fighters, including mahatma gandhi, jawaharlal nehru, chandra shekhar azad, rani lakshmi bai of jhansi, and others, took the initiative in organising the campaign that resulted in indiaâ€™s independence, which was attained thanks to their efforts.']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXAMPLE OF WORD TOKENS"
      ],
      "metadata": {
        "id": "VwDY3ZbmzbAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-vQ2psBzgbl",
        "outputId": "140c2079-29d9-4a81-ed01-15c311b118e9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['freedom', 'fighters']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text preprocessing"
      ],
      "metadata": {
        "id": "JHCAzYtUzuEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "##Lemmatization is the process of reducing a word to its base or dictionary form, known as the lemma\n",
        "def LemTokens(tokens):\n",
        "  return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct),None) for punct in string.punctuation)\n",
        "def LemNormalize(text):\n",
        "  return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
        "\n"
      ],
      "metadata": {
        "id": "1FL5_AFOzyHu"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the greeting function"
      ],
      "metadata": {
        "id": "yOQzjzNFfcri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GREET_INPUTS= (\"Hello\",\" Hi\",\"Greetings\",\"Whats new?\",\"How are you doing\",\"Hey\")\n",
        "GREET_RESPONSE=[\"Hello\",\"Hey\",\"Thanks\",\"hi there\",\"i brought info about freedom fighters\",\"hello\",\"Im good and hoping the same\",\"IM glad that you are talking to me\"]\n",
        "def greet(sentence):\n",
        "\n",
        "    for word in sentence.split():\n",
        "      if word.lower() in GREET_INPUTS:\n",
        "        return random.choice(GREET_RESPONSE)"
      ],
      "metadata": {
        "id": "tm8XWAFTfY_7"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESPONSE GENERATION"
      ],
      "metadata": {
        "id": "5_6cr87xiDU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "JiV7BJteiJUu"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response(user_response):\n",
        "  robo1_response=''\n",
        "  TfidfVec=TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "  tfidf=TfidfVec.fit_transform(sent_tokens)\n",
        "  vals= cosine_similarity(tfidf[-1],tfidf)\n",
        "  idx=vals.argsort()[0][-2]\n",
        "  flat=vals.flatten()\n",
        "  flat.sort()\n",
        "  req_tfidf=flat[-2]\n",
        "  if(req_tfidf==0):\n",
        "    robo1_response=robo1_response+\"I am Sorry! I dont understand you\"\n",
        "    return robo1_response\n",
        "  else:\n",
        "    robo1_response=robo1_response+sent_tokens[idx]\n",
        "    return robo1_response"
      ],
      "metadata": {
        "id": "E0aYYYxui6sr"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flag=True\n",
        "print(\"BOT:Hey my name is SAHA. let's start a conversation! Also, if you want to exit any time, just type Bye!\")\n",
        "while(flag==True):\n",
        "  user_response = input()\n",
        "  user_response=user_response.lower()\n",
        "  if(user_response!='bye'):\n",
        "    if(user_response=='thanks'or user_response=='thankyou'):\n",
        "      flag=False\n",
        "      print(\"Bot:you are welcome..\")\n",
        "    else:\n",
        "       if(greet(user_response)!=None):\n",
        "        print(\"BOT:\"+greet(user_response))\n",
        "       else:\n",
        "        sent_tokens.append(user_response)\n",
        "        word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
        "        final_words=list(set(word_tokens))\n",
        "        print(\"BOT: \",end =\" \")\n",
        "        print(response(user_response))\n",
        "        sent_tokens.remove(user_response)\n",
        "  else:\n",
        "    flag=False\n",
        "    print(\"BOT:Goodbye! Take care :)\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW1otQE5lIwq",
        "outputId": "aad672c6-ec03-4669-d400-4189a6a6f050"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOT:Hey my name is SAHA. let's start a conversation! Also, if you want to exit any time, just type Bye!\n",
            "bye\n",
            "BOT:Goodbye! Take care :)\n"
          ]
        }
      ]
    }
  ]
}